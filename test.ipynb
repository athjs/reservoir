{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9a9649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from reservoirpy.nodes import Reservoir,Ridge, RLS\n",
    "\n",
    "# 1. Chargement avec Pandas\n",
    "df = pd.read_csv('votre_fichier.csv')\n",
    "# Assurez-vous que la colonne date est au bon format\n",
    "df['DateColumn'] = pd.to_datetime(df['DateColumn'])\n",
    "\n",
    "# 2. Linéarisation temporelle (Encodage Cyclique)\n",
    "# On transforme l'heure en coordonnées sinus/cosinus pour préserver la continuité (23h30 est proche de 00h00)\n",
    "df['hour_sin'] = np.sin(2 * np.pi * df['DateColumn'].dt.hour / 24)\n",
    "df['hour_cos'] = np.cos(2 * np.pi * df['DateColumn'].dt.hour / 24)\n",
    "# Optionnel : jour de la semaine\n",
    "df['day_sin'] = np.sin(2 * np.pi * df['DateColumn'].dt.dayofweek / 7)\n",
    "df['day_cos'] = np.cos(2 * np.pi * df['DateColumn'].dt.dayofweek / 7)\n",
    "\n",
    "# 3. Sélection des Features (Temps + Cible) et de la Cible (Target)\n",
    "# On utilise les composantes temporelles et la valeur passée pour prédire le futur\n",
    "features = ['hour_sin', 'hour_cos', 'day_sin', 'day_cos', 'TargetColumn']\n",
    "X_raw = df[features].values\n",
    "Y_raw = df['TargetColumn'].values.reshape(-1, 1)\n",
    "\n",
    "# 4. Création du décalage pour le forecast (Horizon H=10)\n",
    "forecast_horizon = 10\n",
    "X_final = X_raw[:-forecast_horizon]\n",
    "Y_final = Y_raw[forecast_horizon:]\n",
    "\n",
    "# 5. Séparation Train/Test (Séquentielle pour séries temporelles)\n",
    "train_len = int(len(X_final) * 0.8)\n",
    "X_train_raw, Y_train_raw = X_final[:train_len], Y_final[:train_len]\n",
    "X_test_raw, Y_test_raw = X_final[train_len:], Y_final[train_len:]\n",
    "\n",
    "# 6. Normalisation StandardScaler\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train = scaler_x.fit_transform(X_train_raw)\n",
    "Y_train = scaler_y.fit_transform(Y_train_raw).ravel()\n",
    "\n",
    "X_test = scaler_x.transform(X_test_raw)\n",
    "Y_test = scaler_y.transform(Y_test_raw).ravel()\n",
    "\n",
    "dataset = ((X_train, Y_train), (X_test, Y_test))\n",
    "\n",
    "print(f\"Dimensions d'entrée (N_samples, N_features) : {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01199deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoirpy.observables import nrmse, rsquare\n",
    "\n",
    "def objective(dataset, config, **kwargs):\n",
    "    # Récupération sécurisée des hyperparamètres\n",
    "    N = int(kwargs.get(\"N\", 500))\n",
    "    sr = kwargs.get(\"sr\", 1.0)\n",
    "    lr = kwargs.get(\"lr\", 0.5)\n",
    "    iss = kwargs.get(\"iss\", 0.1)\n",
    "    forgetting_factor = kwargs.get(\"forgetting_factor\", 0.99)\n",
    "    reg_prop = kwargs.get(\"reg_prop\", 1e-5)\n",
    "    \n",
    "    train_data, test_data = dataset\n",
    "    X_train, y_train = train_data\n",
    "    X_test, y_test = test_data\n",
    "\n",
    "    # Construction du modèle\n",
    "    reservoir = Reservoir(N, \n",
    "                          lr=lr, \n",
    "                          sr=sr, \n",
    "                          input_scaling=iss, \n",
    "                          rc_connectivity=0.1) # Connectivité standard\n",
    "    \n",
    "    # RLS avec facteur d'oubli (Vital pour l'online learning)\n",
    "    readout = RLS(forgetting_factor=forgetting_factor, \n",
    "                  regularizer=reg_prop)\n",
    "    \n",
    "    model = reservoir >> readout\n",
    "\n",
    "    # Entraînement et Prédiction\n",
    "    try:\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.run(X_test)\n",
    "        \n",
    "        # Calcul de la perte sur les données normalisées (suffisant pour l'optimisation)\n",
    "        loss = nrmse(y_test, predictions)\n",
    "    except Exception as e:\n",
    "        # Gestion des divergences numériques\n",
    "        return {\"loss\": 1000.0, \"status\": \"fail\", \"error\": str(e)}\n",
    "\n",
    "    return {\"loss\": loss, \"status\": \"ok\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8487c05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "  \"exp\": \"esn_rls_optimization\",\n",
    "  \"hp_max_evals\": 50,\n",
    "  \"hp_method\": \"random\",\n",
    "  \"hp_space\": {\n",
    "    \"N\": [\"choice\", [300, 500, 800]],\n",
    "    \"sr\": [\"uniform\", 0.1, 1.5],\n",
    "    \"lr\": [\"loguniform\", 1e-3, 1],\n",
    "    \"iss\": [\"uniform\", 0.01, 1],\n",
    "    \"forgetting_factor\": [\"uniform\", 0.98, 0.9999],\n",
    "    \"reg_prop\": [\"loguniform\", 1e-8, 1e-2]\n",
    "  },\n",
    "  \"seed\": 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5ed162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Instanciation avec les MEILLEURS paramètres trouvés\n",
    "# (Exemple de valeurs, remplacez par best_params['N'], etc.)\n",
    "best_N = 500 \n",
    "best_sr = 0.9\n",
    "best_lr = 0.3\n",
    "best_iss = 0.5\n",
    "best_ff = 0.995 # Forgetting factor\n",
    "best_reg = 1e-5\n",
    "\n",
    "reservoir = Reservoir(best_N, lr=best_lr, sr=best_sr, input_scaling=best_iss)\n",
    "readout = RLS(forgetting_factor=best_ff, regularizer=best_reg)\n",
    "model = reservoir >> readout\n",
    "\n",
    "# 2. Entraînement et Prédiction\n",
    "print(\"Entraînement en cours...\")\n",
    "model.fit(X_train, Y_train)\n",
    "Y_pred_norm = model.run(X_test)\n",
    "\n",
    "# 3. Dénormalisation (Retour aux unités physiques)\n",
    "Y_pred_real = scaler_y.inverse_transform(Y_pred_norm)\n",
    "Y_test_real = scaler_y.inverse_transform(Y_test.reshape(-1, 1))\n",
    "\n",
    "# 4. Calcul des Métriques sur les vraies valeurs\n",
    "score_nrmse = nrmse(Y_test_real, Y_pred_real)\n",
    "score_r2 = rsquare(Y_test_real, Y_pred_real)\n",
    "\n",
    "print(f\"NRMSE Final (Unités Réelles): {score_nrmse:.4f}\")\n",
    "print(f\"R² Final: {score_r2:.4f}\")\n",
    "\n",
    "# 5. Visualisation Professionnelle\n",
    "plt.figure(figsize=(15, 6))\n",
    "# Zoom sur 200 points pour la lisibilité\n",
    "zoom = slice(0, 300) \n",
    "\n",
    "plt.plot(Y_test_real[zoom], label=\"Réel\", color='black', alpha=0.7)\n",
    "plt.plot(Y_pred_real[zoom], label=\"Prédiction ESN\", color='red', linestyle='--')\n",
    "plt.title(f\"Prévision à horizon {forecast_horizon} (Unités physiques)\\nNRMSE: {score_nrmse:.3f}\")\n",
    "plt.ylabel(\"Valeur\")\n",
    "plt.xlabel(\"Temps (pas)\")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# 6. Analyse des Résidus\n",
    "residuals = Y_test_real - Y_pred_real\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.hist(residuals, bins=50, color='gray', edgecolor='black')\n",
    "plt.title(\"Distribution des Erreurs (Résidus)\")\n",
    "plt.xlabel(\"Erreur de prédiction\")\n",
    "plt.ylabel(\"Fréquence\")\n",
    "plt.axvline(0, color='red', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa00cb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reservoir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
