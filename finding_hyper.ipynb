{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14b1127b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import os \n",
    "import math \n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "dpath = 'archive/'\n",
    "\n",
    "#Makes the time a continuous value to work with ESN.\n",
    "def time_linearisation(date): \n",
    "    format_code = \"%Y/%m/%d %H:%M:%S\"\n",
    "    dt = datetime.strptime(date, format_code)\n",
    "    half_hour_index = dt.hour * 2 + (1 if dt.minute >= 30 else 0)\n",
    "    hh_sin = math.sin(2 * math.pi * half_hour_index / 48)\n",
    "    hh_cos = math.cos(2 * math.pi * half_hour_index / 48)\n",
    "\n",
    "    # Week day\n",
    "    dow = dt.weekday()\n",
    "    dow_sin = math.sin(2 * math.pi * dow / 7)\n",
    "    dow_cos = math.cos(2 * math.pi * dow / 7)\n",
    "\n",
    "    # Month day\n",
    "    dom = dt.day - 1\n",
    "    days_in_month = 31  # number of days in a month approximation\n",
    "    dom_sin = math.sin(2 * math.pi * dom / days_in_month)\n",
    "    dom_cos = math.cos(2 * math.pi * dom / days_in_month)\n",
    "\n",
    "    # Months\n",
    "    month = dt.month - 1\n",
    "    month_sin = math.sin(2 * math.pi * month / 12)\n",
    "    month_cos = math.cos(2 * math.pi * month / 12)\n",
    "\n",
    "    return np.array([\n",
    "        hh_sin, hh_cos,\n",
    "        dow_sin, dow_cos,\n",
    "        dom_sin, dom_cos,\n",
    "        month_sin, month_cos\n",
    "    ])\n",
    "obj=[]\n",
    "#Notes Function building the data useful for the training. \n",
    "def gathering_data(csv_reader,current_size, ind ):\n",
    "    here = 0   \n",
    "    if current_size>1500:\n",
    "        for row in csv_reader:\n",
    "            if not row or row[0].startswith(\"R\") or here%6!=0:\n",
    "                continue\n",
    "            data[here + ind ,0:8]= np.array(time_linearisation(row[1]))\n",
    "            data[here + ind ,8]= float(row[2])\n",
    "            data[here + ind ,9] = float(row[3])\n",
    "            here+=1\n",
    "    else :\n",
    "        for row in csv_reader:\n",
    "            if not row or row[0].startswith(\"R\"):\n",
    "                continue\n",
    "            data[here + ind ,0:8]= np.array(time_linearisation(row[1]))\n",
    "            data[here + ind ,8]= float(row[2])\n",
    "            data[here + ind ,9] = float(row[3])\n",
    "            here+=1\n",
    "    return data\n",
    "\n",
    "def size(repo):\n",
    "    lst = os.listdir(\"./archive/\")\n",
    "    lst.sort()\n",
    "    list = []\n",
    "    # sorting to get data in the chronologic time. \n",
    "    for file in lst : \n",
    "        size = 0 \n",
    "        with open(dpath + file, mode = 'r') as file :\n",
    "            csv_reader = csv.reader(file)\n",
    "            for row in csv_reader:\n",
    "                if not row or row[0].startswith(\"R\"):\n",
    "                    continue\n",
    "                size +=1\n",
    "            list.append(size)\n",
    "    return list\n",
    "\n",
    "\n",
    "\n",
    "def correcting_size(repo): \n",
    "    lst = os.listdir(\"./archive/\")\n",
    "    lst.sort()\n",
    "    current= 0 \n",
    "    new_list =[]\n",
    "     # sorting to get data in the chronologic time. \n",
    "    for file in lst : \n",
    "        here =0\n",
    "        size = 0 \n",
    "        if list[current]<1500:\n",
    "            new_list.append(list[current])\n",
    "            current +=1\n",
    "            continue \n",
    "        else : \n",
    "            with open(dpath + file, mode = 'r') as file :\n",
    "                csv_reader = csv.reader(file)\n",
    "                for row in csv_reader:\n",
    "                    if not row or row[0].startswith(\"R\") or here%6!=0:\n",
    "                        here +=1\n",
    "                        continue\n",
    "                    else:\n",
    "                        here+=1\n",
    "                        size  +=1\n",
    "                new_list.append(size)\n",
    "                current+=1\n",
    "    return new_list\n",
    "#Doing it with each file \n",
    "list = size(dpath)\n",
    "final_list = correcting_size(dpath)\n",
    "data = np.zeros((sum(final_list),10))\n",
    "\n",
    "def gathering_all(repo):\n",
    "    lst = os.listdir(\"./archive/\")\n",
    "    lst.sort()\n",
    "    current = 0\n",
    "    ind = 0 \n",
    "    # sorting to get data in the chronologic time. \n",
    "    for file in lst : \n",
    "        with open(dpath + file, mode = 'r') as file :\n",
    "            csv_reader = csv.reader(file)\n",
    "            current_size = list[current]\n",
    "            gathering_data(csv_reader, current_size, ind)\n",
    "        ind += final_list[current]\n",
    "        current +=1\n",
    "        \n",
    "\n",
    "gathering_all(dpath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc095adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoirpy.datasets import to_forecasting\n",
    "x,y= to_forecasting(data, forecast=48)\n",
    "units = 2000 \n",
    "leak_rate = 0.3\n",
    "spectral_radius = 0.1\n",
    "input_scaling = 2.0\n",
    "connectivity = 0.9\n",
    "input_connectivity = 0.2\n",
    "regularization = 1e-1\n",
    "seed = 42\n",
    "X_train1, y_train1 = x[:40000], y[:40000]\n",
    "X_test1, y_test1 = x[40000:], y[40000:]\n",
    "\n",
    "# plot_train_test(X_train1, y_train1, X_test1, y_test1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "359ba2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from reservoirpy.observables import nrmse, rsquare\n",
    "from reservoirpy.nodes import Ridge\n",
    "hyperopt_config = {\n",
    "    \"exp\": \"hyperopt-multiscroll\",    # the experimentation name\n",
    "    \"hp_max_evals\": 200,              # the number of differents sets of parameters hyperopt has to try\n",
    "    \"hp_method\": \"random\",            # the method used by hyperopt to chose those sets (see below)\n",
    "    \"seed\": 42,                       # the random state seed, to ensure reproducibility\n",
    "    \"instances_per_trial\": 5,         # how many random ESN will be tried with each sets of parameters\n",
    "    \"hp_space\": {                     # what are the ranges of parameters explored\n",
    "        \"N\": [\"choice\", 150,250, 500,],             # the number of neurons is fixed to 500\n",
    "        \"sr\": [\"loguniform\", 1e-2, 10],   # the spectral radius is log-uniformly distributed between 1e-2 and 10\n",
    "        \"lr\": [\"loguniform\", 1e-3, 1],    # idem with the leaking rate, from 1e-3 to 1\n",
    "        \"input_scaling\": [\"choice\", 1.0], # the input scaling is fixed\n",
    "        \"ridge\": [\"loguniform\", 1e-8, 1e1],        # and so is the regularization parameter.\n",
    "        \"seed\": [\"choice\", 1234]          # an other random seed for the ESN initialization\n",
    "    }\n",
    "}\n",
    "\n",
    "# we precautionously save the configuration in a JSON file\n",
    "# each file will begin with a number corresponding to the current experimentation run number.\n",
    "with open(f\"{hyperopt_config['exp']}.config.json\", \"w+\") as f:\n",
    "    json.dump(hyperopt_config, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2e4a450",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoirpy.observables import nrmse, rsquare\n",
    "from reservoirpy.nodes import Reservoir, Ridge\n",
    "# Objective functions accepted by ReservoirPy must respect some conventions:\n",
    "#  - dataset and config arguments are mandatory, like the empty '*' expression.\n",
    "#  - all parameters that will be used during the search must be placed after the *.\n",
    "#  - the function must return a dict with at least a 'loss' key containing the result of the loss function.\n",
    "# You can add any additional metrics or information with other keys in the dict. See hyperopt documentation for more informations.\n",
    "def objective(dataset, config, *, input_scaling, N, sr, lr, ridge, seed):\n",
    "    # This step may vary depending on what you put inside 'dataset'\n",
    "    x_train, x_test, y_train, y_test = dataset\n",
    "    \n",
    "    # You can access anything you put in the config file from the 'config' parameter.\n",
    "    instances = config[\"instances_per_trial\"]\n",
    "    \n",
    "    # The seed should be changed across the instances to be sure there is no bias in the results due to initialization.\n",
    "    variable_seed = seed \n",
    "    \n",
    "    losses = []; r2s = [];\n",
    "    for n in range(instances):\n",
    "        # Build your model given the input parameters\n",
    "        reservoir = Reservoir(\n",
    "            units=N, \n",
    "            sr=sr, \n",
    "            lr=lr, \n",
    "            input_scaling=input_scaling, \n",
    "            seed=variable_seed\n",
    "        )\n",
    "\n",
    "        readout = Ridge(ridge=ridge)\n",
    "\n",
    "        model = reservoir >> readout\n",
    "\n",
    "\n",
    "        # Train your model and test your model.\n",
    "        predictions = model.fit(x_train, y_train) \\\n",
    "                           .run(x_test)\n",
    "        \n",
    "        loss = nrmse(y_test, predictions, norm_value=np.ptp(x_train))\n",
    "        r2 = rsquare(y_test, predictions)\n",
    "        \n",
    "        # Change the seed between instances\n",
    "        variable_seed += 1\n",
    "        \n",
    "        losses.append(loss)\n",
    "        r2s.append(r2)\n",
    "\n",
    "    # Return a dictionnary of metrics. The 'loss' key is mandatory when using hyperopt.\n",
    "    return {'loss': np.mean(losses),\n",
    "            'r2': np.mean(r2s)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26107939",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 30000\n",
    "forecast = 10\n",
    "\n",
    "X_train = x[:train_len]\n",
    "Y_train = x[forecast : train_len + forecast]\n",
    "\n",
    "X_test = x[train_len : -forecast]\n",
    "Y_test = x[train_len + forecast:]\n",
    "\n",
    "dataset = (X_train, X_test, Y_train, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "922225e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoirpy.datasets import to_forecasting\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = to_forecasting(x, forecast=forecast, test_size=train_len-forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9236e8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 15/200 [00:18<03:20,  1.08s/trial, best loss=0.0209]/Users/mathisp/Code/S9/reservoir/reservoir/lib/python3.13/site-packages/joblib/externals/loky/process_executor.py:782: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "100%|██████████| 200/200 [02:33<00:00,  1.30trial/s, best loss=0.0199]\n"
     ]
    }
   ],
   "source": [
    "from reservoirpy.hyper import parallel_research\n",
    "best = parallel_research(objective, dataset, f\"{hyperopt_config['exp']}.config.json\", \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "215b2e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoirpy.hyper import plot_hyperopt_report\n",
    "fig = plot_hyperopt_report(hyperopt_config[\"exp\"], (\"lr\", \"sr\", \"ridge\"), metric=\"r2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff2ffcec",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperopt_config1 = {\n",
    "    \"exp\": \"hyperopt1-multiscroll\",    # the experimentation name\n",
    "    \"hp_max_evals\": 200,              # the number of differents sets of parameters hyperopt has to try\n",
    "    \"hp_method\": \"random\",            # the method used by hyperopt to chose those sets (see below)\n",
    "    \"seed\": 42,                       # the random state seed, to ensure reproducibility\n",
    "    \"instances_per_trial\": 5,         # how many random ESN will be tried with each sets of parameters\n",
    "    \"hp_space\": {                     # what are the ranges of parameters explored\n",
    "        \"N\": [\"choice\", 150,250, 500,],             # the number of neurons is fixed to 500\n",
    "        \"sr\": [\"loguniform\", 1e-2, 1],   # the spectral radius is log-uniformly distributed between 1e-2 and 10\n",
    "        \"lr\": [\"loguniform\", 1e-1, 1],    # idem with the leaking rate, from 1e-3 to 1\n",
    "        \"input_scaling\": [\"choice\", 1.0], # the input scaling is fixed\n",
    "        \"ridge\": [\"loguniform\", 1e-2, 1e2],        # and so is the regularization parameter.\n",
    "        \"seed\": [\"choice\", 1234]          # an other random seed for the ESN initialization\n",
    "    }\n",
    "}\n",
    "# we precautionously save the configuration in a JSON file\n",
    "# each file will begin with a number corresponding to the current experimentation run number.\n",
    "with open(f\"{hyperopt_config1['exp']}.config.json\", \"w+\") as f:\n",
    "    json.dump(hyperopt_config1, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5790ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = to_forecasting(x, forecast=forecast, test_size=train_len-forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2bb74a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:29<00:00,  1.34trial/s, best loss=0.0198]\n"
     ]
    }
   ],
   "source": [
    "from reservoirpy.hyper import parallel_research\n",
    "\n",
    "best = parallel_research(objective, dataset, f\"{hyperopt_config1['exp']}.config.json\", \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5a5abca",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_hyperopt_report(hyperopt_config1[\"exp\"], (\"lr\", \"sr\", \"ridge\",), metric=\"r2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reservoir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
