{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "439bbd0b",
   "metadata": {},
   "source": [
    "# Training \n",
    "\n",
    "This file contains the training part of the RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620cf1d8",
   "metadata": {},
   "source": [
    "This cells claims the data on Kaggle thanks to the API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746c062e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import os \n",
    "import math \n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "dpath = '/Users/mathisp/Code/S9/reservoir/archive/'\n",
    "\n",
    "#Makes the time a continuous value to work with ESN.\n",
    "def time_linearisation(date): \n",
    "    format_code = \"%Y/%m/%d %H:%M:%S\"\n",
    "    dt = datetime.strptime(date, format_code)\n",
    "    half_hour_index = dt.hour * 2 + (1 if dt.minute >= 30 else 0)\n",
    "    hh_sin = math.sin(2 * math.pi * half_hour_index / 48)\n",
    "    hh_cos = math.cos(2 * math.pi * half_hour_index / 48)\n",
    "\n",
    "    # Jour de la semaine (0=lundi)\n",
    "    dow = dt.weekday()\n",
    "    dow_sin = math.sin(2 * math.pi * dow / 7)\n",
    "    dow_cos = math.cos(2 * math.pi * dow / 7)\n",
    "\n",
    "    # Jour du mois\n",
    "    dom = dt.day - 1\n",
    "    days_in_month = 31  # approximation suffisante pour encodage cyclique\n",
    "    dom_sin = math.sin(2 * math.pi * dom / days_in_month)\n",
    "    dom_cos = math.cos(2 * math.pi * dom / days_in_month)\n",
    "\n",
    "    # Mois\n",
    "    month = dt.month - 1\n",
    "    month_sin = math.sin(2 * math.pi * month / 12)\n",
    "    month_cos = math.cos(2 * math.pi * month / 12)\n",
    "\n",
    "    return np.array([\n",
    "        hh_sin, hh_cos,\n",
    "        dow_sin, dow_cos,\n",
    "        dom_sin, dom_cos,\n",
    "        month_sin, month_cos\n",
    "    ])\n",
    "obj=[]\n",
    "#Notes Function building the data useful for the training. \n",
    "def gathering_data(csv_reader,current_size, ind ):\n",
    "    here = 0   \n",
    "    if current_size>1500:\n",
    "        for row in csv_reader:\n",
    "            if not row or row[0].startswith(\"R\") or here%6!=0:\n",
    "                continue\n",
    "            data[here + ind ,0:8]= np.array(time_linearisation(row[1]))\n",
    "            data[here + ind ,8]= float(row[2])\n",
    "            data[here + ind ,9] = float(row[3])\n",
    "            here+=1\n",
    "    else :\n",
    "        for row in csv_reader:\n",
    "            if not row or row[0].startswith(\"R\"):\n",
    "                continue\n",
    "            data[here + ind ,0:8]= np.array(time_linearisation(row[1]))\n",
    "            data[here + ind ,8]= float(row[2])\n",
    "            data[here + ind ,9] = float(row[3])\n",
    "            here+=1\n",
    "    return data\n",
    "\n",
    "def size(repo):\n",
    "    lst = os.listdir(\"./archive/\")\n",
    "    lst.sort()\n",
    "    list = []\n",
    "    # sorting to get data in the chronologic time. \n",
    "    for file in lst : \n",
    "        size = 0 \n",
    "        with open(dpath + file, mode = 'r') as file :\n",
    "            csv_reader = csv.reader(file)\n",
    "            for row in csv_reader:\n",
    "                if not row or row[0].startswith(\"R\"):\n",
    "                    continue\n",
    "                size +=1\n",
    "            list.append(size)\n",
    "    return list\n",
    "\n",
    "\n",
    "\n",
    "def correcting_size(repo): \n",
    "    lst = os.listdir(\"./archive/\")\n",
    "    lst.sort()\n",
    "    current= 0 \n",
    "    new_list =[]\n",
    "     # sorting to get data in the chronologic time. \n",
    "    for file in lst : \n",
    "        here =0\n",
    "        size = 0 \n",
    "        if list[current]<1500:\n",
    "            new_list.append(list[current])\n",
    "            current +=1\n",
    "            continue \n",
    "        else : \n",
    "            with open(dpath + file, mode = 'r') as file :\n",
    "                csv_reader = csv.reader(file)\n",
    "                for row in csv_reader:\n",
    "                    if not row or row[0].startswith(\"R\") or here%6!=0:\n",
    "                        here +=1\n",
    "                        continue\n",
    "                    else:\n",
    "                        here+=1\n",
    "                        size  +=1\n",
    "                new_list.append(size)\n",
    "                current+=1\n",
    "    return new_list\n",
    "#Doing it with each file \n",
    "list = size(dpath)\n",
    "final_list = correcting_size(dpath)\n",
    "data = np.zeros((sum(final_list),10))\n",
    "\n",
    "def gathering_all(repo):\n",
    "    lst = os.listdir(\"./archive/\")\n",
    "    lst.sort()\n",
    "    current = 0\n",
    "    ind = 0 \n",
    "    # sorting to get data in the chronologic time. \n",
    "    for file in lst : \n",
    "        with open(dpath + file, mode = 'r') as file :\n",
    "            csv_reader = csv.reader(file)\n",
    "            current_size = list[current]\n",
    "            gathering_data(csv_reader, current_size, ind)\n",
    "        ind += final_list[current]\n",
    "        current +=1\n",
    "        \n",
    "\n",
    "gathering_all(dpath)\n",
    "print(data[96000:])\n",
    "print(sum(final_list),len(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73dc7c44",
   "metadata": {},
   "source": [
    "Building of the ESN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "908e56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "def plot_train_test(X_train, y_train, X_test, y_test):\n",
    "    sample = 30000\n",
    "    test_len = X_test.shape[0]\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "    plt.plot(np.arange(0, 30000), X_train[:sample,9], label=\"Training data\")\n",
    "    plt.plot(np.arange(0, 30000), y_train[:sample,9], label=\"Training ground truth\")\n",
    "    plt.plot(np.arange(30000, 30000+test_len), X_test[:,9], label=\"Testing data\")\n",
    "    plt.plot(np.arange(30000, 30000+test_len), y_test[:,9], label=\"Testing ground truth\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fa7022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoirpy.datasets import to_forecasting\n",
    "x,y= to_forecasting(data, forecast=10)\n",
    "print(len(x))\n",
    "units = 50 \n",
    "leak_rate = 0.3\n",
    "spectral_radius = 1.0\n",
    "input_scaling = 1.0\n",
    "connectivity = 0.1\n",
    "input_connectivity = 0.2\n",
    "regularization = 1e-8\n",
    "seed = 42\n",
    "X_train1, y_train1 = x[:30000], y[:30000]\n",
    "X_test1, y_test1 = x[30000:], y[30000:]\n",
    "plot_train_test(X_train1, y_train1, X_test1, y_test1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d895098",
   "metadata": {},
   "source": [
    "Functions allowing to build and reset the ESN. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "13ae0bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_esn():\n",
    "    from reservoirpy.nodes import Reservoir, Ridge\n",
    "\n",
    "    reservoir = Reservoir(units, input_scaling=input_scaling, sr=spectral_radius,\n",
    "                          lr=leak_rate, rc_connectivity=connectivity,\n",
    "                          input_connectivity=input_connectivity, seed=seed)\n",
    "    readout   = Ridge(ridge=regularization, output_dim=10)\n",
    "\n",
    "    return reservoir >> readout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1d2e8209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoirpy.nodes import Reservoir, Ridge\n",
    "\n",
    "reservoir = Reservoir(units, input_scaling=input_scaling, sr=spectral_radius,\n",
    "                      lr=leak_rate, rc_connectivity=connectivity,\n",
    "                      input_connectivity=input_connectivity, seed=seed)\n",
    "\n",
    "readout   = Ridge(ridge=regularization, output_dim=10)\n",
    "\n",
    "esn = reservoir >> readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "6ec3697b",
   "metadata": {},
   "outputs": [],
   "source": [
    "esn = esn.fit(X_train1, y_train1)\n",
    "def plot_results(y_pred, y_test, sample=30000):\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 7))\n",
    "    plt.subplot(211)\n",
    "    plt.plot(np.arange(sample), y_pred[:sample,8], lw=3, label=\"ESN prediction\")\n",
    "    plt.plot(np.arange(sample), y_test[:sample,8], linestyle=\"--\", lw=2, label=\"True value\")\n",
    "    plt.plot(np.abs(y_test[:sample,8] - y_pred[:sample,8]), label=\"Absolute deviation\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "fd1c49f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = esn.run(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0000cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(y_pred1, y_test1)\n",
    "\n",
    "#This does not work well, we should use online learning to prevent extreme drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "8dc4959a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from reservoirpy.nodes import RLS\n",
    "\n",
    "reservoir = Reservoir(units, input_scaling=input_scaling, sr=spectral_radius,\n",
    "                      lr=leak_rate, rc_connectivity=connectivity,\n",
    "                      input_connectivity=input_connectivity, seed=seed)\n",
    "\n",
    "readout   = RLS(1)\n",
    "\n",
    "\n",
    "esn_online = reservoir >> readout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5807d5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_pre = np.zeros((len(X_train1), 1))\n",
    "\n",
    "for t, (x, y) in enumerate(zip(X_train1, y_train1)):\n",
    "    outputs_pre[t] = esn_online.partial_fit(\n",
    "        x.reshape(1, -1),\n",
    "        np.array([y]).reshape(1, -1)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4bed41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reservoir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
